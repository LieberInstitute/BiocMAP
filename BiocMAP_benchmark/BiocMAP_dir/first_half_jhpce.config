//=============================================================================
//  Hardware and software configuration for pipeline execution at JHPCE
//=============================================================================

env.OMP_NUM_THREADS = 2

params {    
    //-------------------------------------------------------------------------
    //  Annotation-related settings
    //-------------------------------------------------------------------------
    
    gencode_version_human = "34"
    gencode_version_mouse = "M23"
    anno_build = "main" // main or primary (main is canonical seqs only)
    
    //-------------------------------------------------------------------------
    //  Arioc alignment settings; see the following for more info:
    //  
    //    -Arioc docs: https://github.com/RWilton/Arioc/blob/master/Arioc.guide.pdf
    //    -our docs: http://research.libd.org/WGBS-Pipeline/configuration.html#arioc-settings
    //-------------------------------------------------------------------------
    
    // Number of reads per batch per GPU: this scales closely with the amount
    // of GPU memory that will be required, and thus will be GPU-dependent
    batch_size = "128k"
    
    // Different seed widths and hash-value sizes can be set here, potentially
    // affecting alignment sensitivity and GPU memory requirements. Arioc has a
    // "gapped" and "nongapped" lookup table, which each have an associated
    // seed.
    gapped_seed = "hsi25_0_30_CT"
    nongapped_seed = "ssi84_2_30_CT"
    
    // Literal arguments passed to the "gapped" and "nongapped" elements of
    // alignment configs for Arioc, respectively. Variables like "maxJ" and
    // "seedDepth" may be raised to increase sensitivity or lowered to increase
    // speed, for example.
    gapped_args = 'Wmxgs="2,6,5,3" Vt="L,0,1" maxJ="20" seedDepth="4"'
    nongapped_args = 'maxJ="200" maxMismatches="5"'
    
    // Settings that mostly can optimize performance for particular hardware:
    // for example, the "useHinGmem" variable controls whether lookup tables 
    // are placed in GPU memory vs. system memory
    x_args = 'watchdogInterval="60" cgaReserved="24M" useHinGmem="1" useJinGmem="1" useHJinGPmem="1" serialLUTinit="1"'
    
    // The number of GPUs to use for alignment of each sample. It is only
    // recommended to raise this above 1 if there are more GPUs available than
    // samples.
    max_gpus = 3
    
    // Typically, a job scheduler like SLURM or SGE makes sure that a shared
    // GPU is not used by more than one user at once, and sets
    // CUDA_VISIBLE_DEVICES automatically when using a GPU. At JHPCE, the 'gpu'
    // queue puts this responsibility on the user instead
    manually_set_gpu = true
    
    // The percentage of volatile GPU utilization, below which a GPU is
    // considered to be unoccupied, and therefore available to this pipeline
    gpu_perc_usage_cutoff = 10
}

//-----------------------------------------------------------------------------
//  Hardware resource requirements
//-----------------------------------------------------------------------------

executor {
    name = 'sge'
    queueSize = 40
    submitRateLimit = '1 sec'
    exitReadTimeout = '40 min'
}

process {

    cache = 'lenient'
    
    withName: PullReference {
        cpus = 1
        clusterOptions = '-l mem_free=5G,h_vmem=5G'
    }
  
    withName: PrepareReference {
        cpus = 1
        module = 'conda_R/4.1'
        clusterOptions = '-l mem_free=3G,h_vmem=3G'
    }
    
    withName: EncodeReference {
        cpus = 1
        module = 'arioc/1.43'
        clusterOptions = '-l caracol,mf=200G,h_vmem=200G,h_fsize=200G,h_stack=32M'
    }
  
    withName: PreprocessInputs {
        cpus = 1
        module = 'conda_R/4.1'
        clusterOptions = '-l mem_free=3G,h_vmem=3G,h_fsize=300G'
    }
    
    withName: FastQC_Untrimmed {
        cpus = 2
        penv = 'local'
        module = 'fastqc/0.11.8'
        clusterOptions = '-l mem_free=5G,h_vmem=5G'
    }
    
    withName: Trimming {
        cpus = 1
        module = 'trimgalore/0.6.6'
        clusterOptions = '-l mem_free=5G,h_vmem=5G,h_fsize=300G'
    }
    
    withName: WriteAriocConfigs {
        cpus = 1
        module = 'conda_R/4.1'
        clusterOptions = '-l mem_free=2G,h_vmem=2G'
    }
    
    withName: EncodeReads {
        cpus = 2
        penv = 'local'
        module = 'arioc/1.43'
        clusterOptions = '-l caracol,mf=10G,h_vmem=10G,h_fsize=200G'
    }
    
    withName: AlignReads {
        cpus = 8
        penv = 'local'
        module = 'arioc/1.43'
        clusterOptions = '-l caracol,mf=30G,h_vmem=30G,h_fsize=900G,h_stack=16M'
    }
    
    withName: FilterAlignments {
        cpus = 2
        penv = 'local'
        module = 'samtools/1.10:samblaster/0.1.26'
        clusterOptions = '-l mem_free=8G,h_vmem=8G,h_fsize=800G'
    }
    
    withName: MakeRules {
        cpus = 1
        clusterOptions = '-l mem_free=2G,h_vmem=2G'
    }
}
